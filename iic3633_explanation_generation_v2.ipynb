{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vpzp8naLdsHv"
      },
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-RFt7Gb5dHRv"
      },
      "outputs": [],
      "source": [
        "# Reviews CSV (updated)\n",
        "%%capture\n",
        "!wget https://www.dropbox.com/scl/fi/6u1yfcnnf4jqmhedx519u/Reviews.csv?rlkey=xqmvvohkq0i0k7hho79fs43b6&st=mexudbu2&dl=0\n",
        "!mv Reviews.csv?rlkey=xqmvvohkq0i0k7hho79fs43b6 reviews.csv\n",
        "# Metadata for each restaurant\n",
        "!wget https://www.dropbox.com/scl/fi/cxckzuj81gsnlsvclqnza/metadata.json.gz?rlkey=d4xerrcwbeyt09oi01f9f4wru&st=sv6cnpzh&dl=0\n",
        "!mv metadata.json.gz?rlkey=d4xerrcwbeyt09oi01f9f4wru metadata.json.gz\n",
        "# LLaVa Image Descriptions\n",
        "!wget https://www.dropbox.com/scl/fi/50pmwvytozpz0cl1p054f/tiny_LLaVa_images_descriptions.json.gz?rlkey=7vreygmtd16lohs3bx6yvmwdk&st=9568qz84&dl=0\n",
        "!mv tiny_LLaVa_images_descriptions.json.gz?rlkey=7vreygmtd16lohs3bx6yvmwdk tiny_LLaVa_images_descriptions.json.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhqE9ZsQd21X"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RESzZ2kBd5iN",
        "outputId": "a1f2553b-488a-4e44-cf76-edde54dde9ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# HuggingFace requirements\n",
        "!pip install transformers datasets evaluate accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaZN6MPQBl-o",
        "outputId": "bed37c2f-a97e-4621-b131-1ce71c22729d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "W2MYzqG1xlbe"
      },
      "outputs": [],
      "source": [
        "# HuggingFace\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "import torch\n",
        "# Data visualization and manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oXArVa_pnQIf"
      },
      "outputs": [],
      "source": [
        "# Metadata\n",
        "import gzip\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x9ynk76Bs_0",
        "outputId": "dfd26ed7-cf2e-4453-b5c3-033bcb5dc47f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Evaluation\n",
        "import copy\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk import word_tokenize\n",
        "from nltk.translate import meteor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiuGcpNOfha5"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSBidukxfggd",
        "outputId": "d929bd09-0406-43a8-d60d-3d19736a95b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño dataset: (8334, 9)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 8038 entries, 0 to 8333\n",
            "Data columns (total 9 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   Unnamed: 0    8038 non-null   int64 \n",
            " 1   user_id       8038 non-null   object\n",
            " 2   gmap_id       8038 non-null   object\n",
            " 3   rating        8038 non-null   int64 \n",
            " 4   text          8038 non-null   object\n",
            " 5   img_url       8038 non-null   object\n",
            " 6   img_filename  8038 non-null   object\n",
            " 7   state         8038 non-null   object\n",
            " 8   rest_id       8038 non-null   int64 \n",
            "dtypes: int64(3), object(6)\n",
            "memory usage: 628.0+ KB\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('reviews.csv')\n",
        "print(f\"Tamaño dataset: {df.shape}\")\n",
        "\n",
        "# Eliminamos datos nulos ...\n",
        "df = df.dropna()\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LkprfiHwmxmz"
      },
      "outputs": [],
      "source": [
        "# Obtenemos el json de la metadata\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'r')\n",
        "  for l in g:\n",
        "    yield json.loads(l)\n",
        "\n",
        "metadata = list(parse('metadata.json.gz'))\n",
        "metadata = metadata[0]\n",
        "# Obtenemos json de descripciones de imagenes\n",
        "descriptions = list(parse('tiny_LLaVa_images_descriptions.json.gz'))\n",
        "descriptions = descriptions[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PFB_Izt0mxj7"
      },
      "outputs": [],
      "source": [
        "# indice metadata\n",
        "new_metadata = []\n",
        "for value in metadata.values():\n",
        "    new_metadata.extend(value)\n",
        "idx2metadata = {}\n",
        "for data in new_metadata:\n",
        "    gmap_id = data['gmap_id']\n",
        "    del data['gmap_id']\n",
        "    idx2metadata[gmap_id] = data\n",
        "# indice descripcion\n",
        "idx2description = {}\n",
        "for key, data in descriptions.items():\n",
        "    key = key.split(\"/\")[-1].split(\".\")[0]\n",
        "    idx2description[key] = data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI6_mhTBlq3a"
      },
      "source": [
        "## Review Generation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM-1P63_O1j8"
      },
      "source": [
        "#### Flan T5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OYkCOCdR_2-y"
      },
      "outputs": [],
      "source": [
        "def generate_review(user_id, item_id, image, previous_reviews, model, tokenizer, print_prompt):\n",
        "    \"\"\"\n",
        "    Genera una review a partir de uid, itid, y una concatenación de previous reviews. Retorna la review generada.\n",
        "    \"\"\"\n",
        "    service_options = \"N/A\"\n",
        "    if 'MISC' in idx2metadata[item_id] and 'Service options' in idx2metadata[item_id]['MISC']:\n",
        "        service_options = \", \".join(idx2metadata[item_id]['MISC']['Service options'])\n",
        "\n",
        "    prompt = f\"\"\"Provide a detailed and unique recommendation for the following restaurant. Use the provided details and avoid repeating information unnecessarily. Highlight the restaurant's features, customer experience, and what makes it stand out. Tailor the recommendation based on the context and information available.\n",
        "\n",
        "### Restaurant Details ###\n",
        "Name: {idx2metadata[item_id]['name']}\n",
        "Average Rating: {idx2metadata[item_id]['avg_rating']}\n",
        "Description: {idx2metadata[item_id]['description']}\n",
        "Categories: {\", \".join(idx2metadata[item_id]['category'])}\n",
        "Service Options: {service_options}\n",
        "Image Description: {image}\n",
        "\n",
        "### Previous Reviews ###\n",
        "{previous_reviews if previous_reviews else 'No reviews available'}\n",
        "\n",
        "### Guideline for Writing the Recommendation ###\n",
        "- Highlight the unique features of the restaurant (e.g., menu items, ambiance, service quality).\n",
        "- Tailor the response based on available service options (e.g., delivery, takeaway, or dine-in).\n",
        "- If relevant, mention scenarios or audiences for whom the restaurant is ideal (e.g., families, couples, groups).\n",
        "- Avoid using the exact same phrasing repeatedly, and do not copy this example directly.\n",
        "\n",
        "Now, write a tailored recommendation based on the above information, keep it concise.\"\"\"\n",
        "    if (print_prompt):\n",
        "      print(\"Prompt:\\n----------------------\\n\" + prompt + \"\\n----------------------\\n\")\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "    outputs = model.generate(\n",
        "        inputs,\n",
        "        max_new_tokens=250,\n",
        "        no_repeat_ngram_size=3,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.9\n",
        "    )\n",
        "    generated_review = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    #print(\"Tokenized Input:\", tokenizer.decode(inputs[0]))\n",
        "    #print(\"Model Raw Output:\", tokenizer.decode(outputs[0]))\n",
        "    return generated_review.strip()\n",
        "\n",
        "def generate_review_for_user_item_pair(user_id, item_id, df, model, tokenizer, print_prompt):\n",
        "    \"\"\"\n",
        "    Recolecta hasta 3 reviews previas del usuario y genera una review a partir de uid y itid. Retorna la review generada.\n",
        "    \"\"\"\n",
        "    # Par usuario-restaurante específico\n",
        "    row = df[(df['user_id'] == user_id) & (df['gmap_id'] == item_id)]\n",
        "    row = row.iloc[0]\n",
        "\n",
        "    rating = row.get('rating')\n",
        "    if rating is None or np.isnan(rating):  # Si rating no existe, utilizamos promedio\n",
        "        rating = idx2metadata[item_id]['avg_rating']\n",
        "    image_description = idx2description[item_id]\n",
        "    # Obtenemos reviews pasadas del restaurante con ratings similares\n",
        "    restaurant_reviews = df[(df['gmap_id'] == item_id) & (df['rating'].isin([rating - 1, rating, rating + 1]))].head(3)\n",
        "    # Eliminamos la review del usuario objetivo\n",
        "    restaurant_reviews = restaurant_reviews[restaurant_reviews['user_id'] != user_id]\n",
        "    previous_reviews = \"\\n* \".join(restaurant_reviews['text'])\n",
        "    context = previous_reviews\n",
        "\n",
        "    return generate_review(user_id, item_id, image_description, context, model, tokenizer, print_prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKLBaZTp_t23",
        "outputId": "2c8d500a-da46-4bd6-efe9-fcbde68a4469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ],
      "source": [
        "# Cargamos modelo flat T5 de huggingface\n",
        "model_name = \"google/flan-t5-large\"\n",
        "model_flan_t5 = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "tokenizer_flan_t5 = T5Tokenizer.from_pretrained(model_name)\n",
        "#tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lUhGjCPwt3z"
      },
      "source": [
        "### Generar Explicación Con Flan-T5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWLzFzoRwt3z"
      },
      "source": [
        "### Elegir par usuario, restaurante"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7c1qNULLyUJJ"
      },
      "outputs": [],
      "source": [
        "# Obtenemos row aleatoriamente\n",
        "random_row = df.sample(1) # Para elegir usuario manualmente cambiar esta linea\n",
        "user_id = random_row['user_id'].values[0]\n",
        "item_id = random_row['gmap_id'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFsZRd91GSeW",
        "outputId": "651f1a00-a4fe-45f6-b058-6066ac90f252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'Dairy Queen', 'address': 'Dairy Queen, 1804 N 13th St, Bismarck, ND 58501', 'description': 'Soft-serve ice cream & signature shakes top the menu at this classic burger & fries fast-food chain.', 'latitude': 46.8252063, 'longitude': -100.77257279999999, 'category': ['Fast food restaurant', 'Ice cream shop'], 'avg_rating': 4, 'num_of_reviews': 333, 'price': '$', 'hours': [['Monday', '10AM–10PM'], ['Tuesday', '10AM–10PM'], ['Wednesday', '10AM–10PM'], ['Thursday', '10AM–10PM'], ['Friday', '10AM–10PM'], ['Saturday', '10AM–10PM'], ['Sunday', '10AM–10PM']], 'MISC': {'Service options': ['Outdoor seating', 'Delivery', 'Takeout'], 'Highlights': ['Fast service'], 'Popular for': ['Lunch', 'Solo dining'], 'Accessibility': ['Wheelchair accessible entrance', 'Wheelchair accessible parking lot', 'Wheelchair accessible restroom', 'Wheelchair accessible seating'], 'Offerings': ['Coffee', \"Kids' menu\", 'Quick bite'], 'Dining options': ['Dessert', 'Seating'], 'Amenities': ['Good for kids', 'High chairs'], 'Atmosphere': ['Casual'], 'Crowd': ['Family-friendly', 'Groups'], 'Payments': ['NFC mobile payments']}, 'state': 'Closes soon ⋅ 10PM ⋅ Opens 10AM Tue', 'relative_results': ['0x52d7824daea68381:0xaa41acaba1c8a50e', '0x52d7825318857c13:0x7bc422e0d8d65f4b', '0x52d7824d0b36121b:0xaa7a9332e3b67c5b', '0x52d78254d12f6543:0xf0331fcaa2a77b1', '0x52d7824bd7ed1991:0x1db96b7e006a692e'], 'url': 'https://www.google.com/maps/place//data=!4m2!3m1!1s0x52d783aacb340d7d:0xa92c8470b406bf32?authuser=-1&hl=en&gl=us'}\n"
          ]
        }
      ],
      "source": [
        "print(idx2metadata[item_id]) # Imprimimos metadata del restaurante para saber que estamos recomendando"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "wHtI7yerKqcb",
        "outputId": "296809f3-1f78-4df2-dba8-bf5b4adbd780"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "generate_review_for_user_item_pair() missing 1 required positional argument: 'print_prompt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-2dca5120718f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generamos Explicación\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerated_review\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_review_for_user_item_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_flan_t5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_flan_t5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n\\nExplicación generada: \\n{generated_review}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n\\nExplicación real: \\n{df[(df['user_id'] == user_id) & (df['gmap_id'] == item_id)]['text'].values[0]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: generate_review_for_user_item_pair() missing 1 required positional argument: 'print_prompt'"
          ]
        }
      ],
      "source": [
        "# Generamos Explicación\n",
        "generated_review = generate_review_for_user_item_pair(user_id, item_id, df, model_flan_t5, tokenizer_flan_t5)\n",
        "print(f\"\\n\\nExplicación generada: \\n{generated_review}\")\n",
        "print(f\"\\n\\nExplicación real: \\n{df[(df['user_id'] == user_id) & (df['gmap_id'] == item_id)]['text'].values[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jelLY2NHLMgz"
      },
      "source": [
        "\n",
        "\n",
        "1.   Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., ... & Liu, P. J. (2020). Exploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res., 21(140), 1-67.\n",
        "https://huggingface.co/google-t5/t5-base#uses\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CehJNDVzy-hN"
      },
      "source": [
        "## HuggingFace SMOL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMFiM82y205X"
      },
      "outputs": [],
      "source": [
        "def generate_review_hugging_face(user_id, item_id, image, previous_reviews, model, tokenizer, print_prompt):\n",
        "    \"\"\"\n",
        "    Genera una review a partir de uid, itid, y una concatenación de previous reviews. Retorna la review generada.\n",
        "    \"\"\"\n",
        "    service_options = \"\"\n",
        "    if 'MISC' in idx2metadata[item_id] and 'Service options' in idx2metadata[item_id]['MISC']:\n",
        "        service_options = \", \".join(idx2metadata[item_id]['MISC']['Service options'])\n",
        "\n",
        "    prompt = f\"\"\"Provide a detailed and unique recommendation for the following restaurant. Use the provided details and avoid repeating information unnecessarily. Highlight the restaurant's features, customer experience, and what makes it stand out. Tailor the recommendation based on the context and information available.\n",
        "\n",
        "### Restaurant Details ###\n",
        "Name: {idx2metadata[item_id]['name']}\n",
        "Average Rating: {idx2metadata[item_id]['avg_rating']}\n",
        "Description: {idx2metadata[item_id]['description']}\n",
        "Categories: {\", \".join(idx2metadata[item_id]['category'])}\n",
        "Service Options: {service_options}\n",
        "Image Description: {image}\n",
        "\n",
        "### Previous Reviews ###\n",
        "{previous_reviews if previous_reviews else 'No reviews available'}\n",
        "\n",
        "### Guideline for Writing the Recommendation ###\n",
        "- Highlight the unique features of the restaurant (e.g., menu items, ambiance, service quality).\n",
        "- Tailor the response based on available service options (e.g., delivery, takeaway, or dine-in).\n",
        "- If relevant, mention scenarios or audiences for whom the restaurant is ideal (e.g., families, couples, groups).\n",
        "- Avoid using the exact same phrasing repeatedly, and do not copy this example directly.\n",
        "\n",
        "Now, write a tailored recommendation based on the above information, keep it concise.\"\"\"\n",
        "    if (print_prompt):\n",
        "      print(\"Prompt:\\n----------------------\\n\" + prompt + \"\\n----------------------\\n\")\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    input_text= hugging_face_tokenizer.apply_chat_template(messages, tokenize=False)\n",
        "    inputs = hugging_face_tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
        "    outputs = hugging_face_model.generate(inputs, max_new_tokens=250, temperature=0.2, top_p=0.9, do_sample=True)\n",
        "    result = tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True)\n",
        "    return result.strip()\n",
        "\n",
        "\n",
        "\n",
        "def generate_review_for_user_item_pair_hugging_face(user_id, item_id, df, model, tokenizer, print_prompt):\n",
        "    \"\"\"\n",
        "    Recolecta hasta 3 reviews previas del usuario y genera una review a partir de uid y itid. Retorna la review generada.\n",
        "    \"\"\"\n",
        "    # Par usuario-restaurante específico\n",
        "    row = df[(df['user_id'] == user_id) & (df['gmap_id'] == item_id)]\n",
        "    row = row.iloc[0]\n",
        "\n",
        "    rating = row.get('rating')\n",
        "    if rating is None or np.isnan(rating):  # Si rating no existe, utilizamos promedio\n",
        "        rating = idx2metadata[item_id]['avg_rating']\n",
        "    image_url = row['img_url']\n",
        "    image_description = descriptions.get(image_url, \"NA\")\n",
        "    # Obtenemos reviews pasadas del usuario con ratings similares\n",
        "    user_reviews = df[(df['user_id'] == user_id) & (df['rating'].isin([rating - 1, rating, rating + 1]))].head(3)\n",
        "    # Eliminamos la review del restaurant objetivo\n",
        "    user_reviews = user_reviews[user_reviews['gmap_id'] != item_id]\n",
        "    previous_reviews = \"\\n* \".join(user_reviews['text'])\n",
        "    context = previous_reviews\n",
        "\n",
        "    return generate_review_hugging_face(user_id, item_id, image_description, context, model, tokenizer, print_prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXvCZSMZy9iB"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "checkpoint = \"HuggingFaceTB/SmolLM2-1.7B-Instruct\"\n",
        "\n",
        "device = \"cpu\" # for GPU usage or \"cpu\" for CPU usage\n",
        "hugging_face_tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "hugging_face_model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgmoM10Pwt34"
      },
      "source": [
        "### Generar Explicación con SmolLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwRGuKuLwt34"
      },
      "source": [
        "### Definir par usuario, restaurante"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLYM_Kfhwt35"
      },
      "outputs": [],
      "source": [
        "# Obtenemos row aleatoriamente\n",
        "random_row = df.sample(1) # Para elegir usuario manualmente cambiar esta linea\n",
        "user_id = random_row['user_id'].values[0]\n",
        "item_id = random_row['gmap_id'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLHWiB78wt35"
      },
      "outputs": [],
      "source": [
        "print(idx2metadata[item_id]) # Imprimimos metadata del restaurante para saber que estamos recomendando"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fvFv0uD358V"
      },
      "outputs": [],
      "source": [
        "# Generamos review\n",
        "generated_review = generate_review_for_user_item_pair_hugging_face(user_id, item_id, df, hugging_face_model, hugging_face_tokenizer)\n",
        "print(f\"\\n\\nReview generada: \\n{generated_review}\")\n",
        "print(f\"\\n\\nReview real: \\n{df[(df['user_id'] == user_id) & (df['gmap_id'] == item_id)]['text'].values[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c10MF3nC4Djc"
      },
      "source": [
        "1. Allal, L. B., Lozhkov, A., Bakouch, E., Blázquez, G. M., Tunstall, L., Piqueres, A., Marafioti, A., Zakka, C., von Werra, L., & Wolf, T. (2024). SmolLM2 - with great data, comes great performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A87yE3EkFkl4"
      },
      "source": [
        "# Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "yiEGBDAOFmB0"
      },
      "outputs": [],
      "source": [
        "# https://www.digitalocean.com/community/tutorials/automated-metrics-for-evaluating-generated-text\n",
        "def calculate_bleu(candidate, reference):\n",
        "    '''\n",
        "    candidate, reference: generated and ground-truth sentences\n",
        "    '''\n",
        "    reference = word_tokenize(reference)\n",
        "    candidate = word_tokenize(candidate)\n",
        "    smoothing = SmoothingFunction().method1\n",
        "    score = sentence_bleu([reference], candidate, smoothing_function=smoothing)\n",
        "    return round(score, 4)\n",
        "\n",
        "def calculate_meteor(candidate, reference):\n",
        "  '''\n",
        "  candidate, reference: tokenized list of words in the sentence\n",
        "  '''\n",
        "  reference = word_tokenize(reference)\n",
        "  candidate = word_tokenize(candidate)\n",
        "  meteor_score = round(meteor([candidate],reference), 4)\n",
        "  return meteor_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXX70dQPwt36"
      },
      "source": [
        "### Evaluation of single case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evv4mkMaHEqh",
        "outputId": "c33b6ed8-b393-4b6b-d0ed-dd196edecfde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU: 0.0036\n",
            "METEOR: 0.1153\n"
          ]
        }
      ],
      "source": [
        "# Buscamos review del user a ese item\n",
        "user_reviews = df[(df['user_id'] == user_id) & (df['gmap_id'] == item_id)]\n",
        "print(f\"BLEU: {calculate_bleu(generated_review, user_reviews['text'].values[0])}\")\n",
        "print(f\"METEOR: {calculate_meteor(generated_review, user_reviews['text'].values[0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-ARpUMW8Uhd"
      },
      "source": [
        "### Flan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LGQciKDvJHhh",
        "outputId": "bb92cf7a-a98c-4e1c-c085-6b70f0896025"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generando 0\n",
            "Prompt:\n",
            "----------------------\n",
            "Provide a detailed and unique recommendation for the following restaurant. Use the provided details and avoid repeating information unnecessarily. Highlight the restaurant's features, customer experience, and what makes it stand out. Tailor the recommendation based on the context and information available.\n",
            "\n",
            "### Restaurant Details ###\n",
            "Name: Espresso Portuguese American Grill\n",
            "Average Rating: 4.5\n",
            "Description: Portuguese-style seafood, steak & sandwiches typify the menu at this rustic European eatery.\n",
            "Categories: Portuguese restaurant, American restaurant, Bar & grill, Beer hall, Catering food and drink supplier, Caterer, Liquor wholesaler, Mediterranean restaurant, Party planner, Wine bar\n",
            "Service Options: Curbside pickup, Delivery, Takeout, Dine-in\n",
            "Image Description: The image features a dining table with a plate of food on it, including a serving of chicken and a serving of broccoli. There are two people sitting at the table, one on the left side and the other on the right side. They appear to be enjoying their meal together.\n",
            "\n",
            "In addition to the food, there are several cups placed around the table, suggesting that they might be drinking beverages while eating. A bottle can also be seen on the table, possibly containing a drink or condiment. The overall scene conveys a casual dining atmosphere.\n",
            "\n",
            "### Previous Reviews ###\n",
            "No reviews available\n",
            "\n",
            "### Guideline for Writing the Recommendation ###\n",
            "- Highlight the unique features of the restaurant (e.g., menu items, ambiance, service quality).\n",
            "- Tailor the response based on available service options (e.g., delivery, takeaway, or dine-in).\n",
            "- If relevant, mention scenarios or audiences for whom the restaurant is ideal (e.g., families, couples, groups).\n",
            "- Avoid using the exact same phrasing repeatedly, and do not copy this example directly.\n",
            "\n",
            "Now, write a tailored recommendation based on the above information, keep it concise.\n",
            "----------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-36-9cef8a00df41>\", line 10, in <cell line: 5>\n",
            "    generated_review = generate_review_for_user_item_pair(user_id, item_id, df, model_flan_t5, tokenizer_flan_t5)\n",
            "  File \"<ipython-input-24-2c42533d08b8>\", line 63, in generate_review_for_user_item_pair\n",
            "    return generate_review(user_id, item_id, image_description, context, model, tokenizer)\n",
            "  File \"<ipython-input-24-2c42533d08b8>\", line 31, in generate_review\n",
            "    outputs = model.generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\", line 2027, in generate\n",
            "    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\", line 635, in _prepare_encoder_decoder_kwargs_for_generation\n",
            "    model_kwargs[\"encoder_outputs\"]: ModelOutput = encoder(**encoder_kwargs)  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\", line 1124, in forward\n",
            "    layer_outputs = layer_module(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\", line 725, in forward\n",
            "    hidden_states = self.layer[-1](hidden_states)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\", line 339, in forward\n",
            "    forwarded_states = self.DenseReluDense(forwarded_states)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\", line 322, in forward\n",
            "    hidden_states = self.wo(hidden_states)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 875, in getmodule\n",
            "    f = getabsfile(module)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 844, in getabsfile\n",
            "    _filename = getsourcefile(object) or getfile(object)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 826, in getsourcefile\n",
            "    if os.path.exists(filename):\n",
            "  File \"/usr/lib/python3.10/genericpath.py\", line 19, in exists\n",
            "    os.stat(path)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-9cef8a00df41>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mitem_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gmap_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mgenerated_review\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_review_for_user_item_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_flan_t5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_flan_t5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0muser_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gmap_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mitem_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-2c42533d08b8>\u001b[0m in \u001b[0;36mgenerate_review_for_user_item_pair\u001b[0;34m(user_id, item_id, df, model, tokenizer)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgenerate_review\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-2c42533d08b8>\u001b[0m in \u001b[0;36mgenerate_review\u001b[0;34m(user_id, item_id, image, previous_reviews, model, tokenizer)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     outputs = model.generate(\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2026\u001b[0m             \u001b[0;31m# if model is encoder decoder encoder_outputs are created and added to `model_kwargs`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2027\u001b[0;31m             model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n\u001b[0m\u001b[1;32m   2028\u001b[0m                 \u001b[0minputs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name, generation_config)\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_input_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModelOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1125\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0;31m# Apply Feed Forward layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mforwarded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mforwarded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseReluDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ],
      "source": [
        "# Generamos reviews para 20 pares de user id e item id de manera aleatoria y evaluamos\n",
        "num_pairs = 20\n",
        "bleu_scores = []\n",
        "meteor_scores = []\n",
        "for i in range(num_pairs):\n",
        "    print(f\"Generando {i}\")\n",
        "    random_row = df.sample(1)\n",
        "    user_id = random_row['user_id'].values[0]\n",
        "    item_id = random_row['gmap_id'].values[0]\n",
        "    generated_review = generate_review_for_user_item_pair(user_id, item_id, df, model_flan_t5, tokenizer_flan_t5, False)\n",
        "    user_reviews = df[(df['user_id'] == user_id) & (df['gmap_id'] == item_id)]\n",
        "    bleu_scores.append(calculate_bleu(generated_review, user_reviews['text'].values[0]))\n",
        "    meteor_scores.append(calculate_meteor(generated_review, user_reviews['text'].values[0]))\n",
        "    if i % 10 == 0:\n",
        "      print(f\"BLEU promedio: {np.mean(bleu_scores)}\")\n",
        "      print(f\"METEOR promedio: {np.mean(meteor_scores)}\")\n",
        "print(f\"BLEU promedio FINAL: {np.mean(bleu_scores)}\")\n",
        "print(f\"METEOR promedio FINAL: {np.mean(meteor_scores)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FqmEh0r8Z8U"
      },
      "source": [
        "### SmolLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyKxJtVhVceE",
        "outputId": "9586249b-776b-4814-f178-aa97af6b43fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generando 0\n",
            "BLEU promedio: 0.0026\n",
            "METEOR promedio: 0.04\n",
            "Generando 1\n",
            "Generando 2\n",
            "Generando 3\n",
            "Generando 4\n",
            "Generando 5\n",
            "Generando 6\n",
            "Generando 7\n",
            "Generando 8\n",
            "Generando 9\n",
            "Generando 10\n",
            "BLEU promedio: 0.0035181818181818187\n",
            "METEOR promedio: 0.09578181818181818\n",
            "Generando 11\n",
            "Generando 12\n",
            "Generando 13\n",
            "Generando 14\n",
            "Generando 15\n",
            "Generando 16\n",
            "Generando 17\n",
            "Generando 18\n",
            "Generando 19\n",
            "Generando 20\n",
            "BLEU promedio: 0.0033571428571428567\n",
            "METEOR promedio: 0.08410952380952381\n",
            "Generando 21\n",
            "Generando 22\n",
            "Generando 23\n",
            "Generando 24\n",
            "Generando 25\n",
            "Generando 26\n",
            "Generando 27\n",
            "Generando 28\n",
            "Generando 29\n",
            "BLEU promedio FINAL: 0.003263333333333333\n",
            "METEOR promedio FINAL: 0.08295666666666665\n"
          ]
        }
      ],
      "source": [
        "# Generamos reviews para 20 pares de user id e item id de manera aleatoria y evaluamos\n",
        "num_pairs = 20\n",
        "bleu_scores = []\n",
        "meteor_scores = []\n",
        "for i in range(num_pairs):\n",
        "    print(f\"Generando {i}\")\n",
        "    random_row = df.sample(1)\n",
        "    user_id = random_row['user_id'].values[0]\n",
        "    item_id = random_row['gmap_id'].values[0]\n",
        "    generated_review = generate_review_for_user_item_pair_hugging_face(user_id, item_id, df, hugging_face_model, hugging_face_tokenizer)\n",
        "    user_reviews = df[(df['user_id'] == user_id) & (df['gmap_id'] == item_id)]\n",
        "    bleu_scores.append(calculate_bleu(generated_review, user_reviews['text'].values[0]))\n",
        "    meteor_scores.append(calculate_meteor(generated_review, user_reviews['text'].values[0]))\n",
        "    if i % 10 == 0:\n",
        "      print(f\"BLEU promedio: {np.mean(bleu_scores)}\")\n",
        "      print(f\"METEOR promedio: {np.mean(meteor_scores)}\")\n",
        "print(f\"BLEU promedio FINAL: {np.mean(bleu_scores)}\")\n",
        "print(f\"METEOR promedio FINAL: {np.mean(meteor_scores)}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}